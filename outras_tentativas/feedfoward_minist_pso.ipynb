{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "# Carregando dataset mnist\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import pyswarms as ps\r\n",
    "import mnist_loader\r\n",
    "\r\n",
    "training_data, validation_data, test_data = mnist_loader.load_data_wrapper()\r\n",
    "training_data = list(training_data)\r\n",
    "\r\n",
    "# Guardando dados de entrada e as saídas desejadas para cada amostra de treinamento\r\n",
    "amostras = []\r\n",
    "y_desejado = []\r\n",
    "p = 0\r\n",
    "for amostra in training_data:  \r\n",
    "    aux = []\r\n",
    "    for i in amostra[0]:\r\n",
    "        aux.append(i[0])\r\n",
    "        \r\n",
    "    amostras.append(aux)\r\n",
    "    \r\n",
    "    aux = []\r\n",
    "    for i in amostra[1]:\r\n",
    "        aux.append(i[0])\r\n",
    "    y_desejado.append(aux)\r\n",
    "    \r\n",
    "    if p == 499:\r\n",
    "        break\r\n",
    "    p += 1\r\n",
    "\r\n",
    "amostras = np.array(amostras)\r\n",
    "y_desejado = np.array(y_desejado)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Parâmetros da rede neural"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "# Arquiteura da rede neural\r\n",
    "n_entrada = 784                # número de entradas na camada de entrada\r\n",
    "n_oculta = 30                  # número de neurônios na camada oculta\r\n",
    "n_saida = 10                   # número de classes na camada de saídas"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Ativação, propagação e compração dos resultados"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "# Propagação direta da rede neural\r\n",
    "def propagacao(particula):\r\n",
    "    y_1 = ativacao1(particula)\r\n",
    "    n = len(amostras)\r\n",
    "    probs = ativacao2(y_1)\r\n",
    "    erro = calculaErro(probs, n)\r\n",
    "    return erro\r\n",
    "\r\n",
    "def calculaErro(probs, n_amostras):\r\n",
    "    # Matriz de confusão do erro\r\n",
    "    correct_logprobs = np.zeros(n_amostras)\r\n",
    "    aux = []\r\n",
    "    for j in range(n_amostras):\r\n",
    "        for k in range(len(probs[j])):\r\n",
    "            if probs[j][k] == y_desejado[j][k]:\r\n",
    "                aux.append(probs[j][k])\r\n",
    "            else:\r\n",
    "                aux.append((probs[j][k]-y_desejado[j][k])**2)\r\n",
    "        correct_logprobs[j] = aux[j]\r\n",
    "    \r\n",
    "    # Calcula o erro da saída de rede\r\n",
    "    #corect_logprobs = -np.log(probs[range(n_amostras), y_desejado]) # erro por saída\r\n",
    "    erro = np.sum(correct_logprobs) / len(amostras)                   # erro médio total\r\n",
    "    return erro\r\n",
    "\r\n",
    "def ativacao2(y_1):\r\n",
    "    # Ativação da camada de saída pela função de softmax\r\n",
    "    exp_scores = np.exp(y_1)\r\n",
    "    probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\r\n",
    "    return probs\r\n",
    "\r\n",
    "def ativacao1(p):\r\n",
    "    # Construindo vetores iniciais de pesos e bias a partir da lista de parâmetros\r\n",
    "    W1 = p[0:23520].reshape((n_entrada,n_oculta))       # pesos oculta-entrada\r\n",
    "    b1 = p[23520:23550].reshape((n_oculta,))            # bias oculta-entrada\r\n",
    "    W2 = p[23550:23850].reshape((n_oculta,n_saida))     # pesos saída-oculta\r\n",
    "    b2 = p[23850:23860].reshape((n_saida,))             # bias saída-oculta\r\n",
    "\r\n",
    "    # Ativando camada oculta pela função de ativação sigmoid\r\n",
    "    z1 = amostras.dot(W1) + b1      # nets da camada oculta\r\n",
    "    a1 = np.tanh(z1)                # ativação da camada oculta\r\n",
    "    y_1 = a1.dot(W2) + b2      # nets da camada de saída\r\n",
    "    return y_1                 # saídas da rede neural"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Execução do PSO para otimização"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "\"\"\"import pso\r\n",
    "\r\n",
    "otimizacao = pso.Pso(100, 100)\r\n",
    "lb = np.array([-1] * dimensoes)\r\n",
    "ub = np.array([1] * dimensoes)\r\n",
    "posicao, custo = otimizacao.run(avaliacao, lb, ub)\"\"\"\r\n",
    "\r\n",
    "def funcao_obj(enxame):\r\n",
    "    n_particulas = enxame.shape[0]\r\n",
    "    enxame = [propagacao(enxame[i]) for i in range(n_particulas)]\r\n",
    "    return np.array(enxame)\r\n",
    "\r\n",
    "# Definindo fator de aceleração 1 e 2 e peso de inércia para o PSO\r\n",
    "parametrosPSO = {'c1': 0.5, 'c2': 0.3, 'w':0.9}\r\n",
    "dimensoes = (n_entrada * n_oculta) + (n_oculta * n_saida) + n_oculta + n_saida\r\n",
    "n_particulas = 100\r\n",
    "n_iteracoes = 50\r\n",
    "\r\n",
    "# Iniciando PSO\r\n",
    "otimizacao = ps.single.GlobalBestPSO(n_particles=n_particulas, dimensions=dimensoes, options=parametrosPSO)\r\n",
    "\r\n",
    "# Realizando treinamento/otimização\r\n",
    "custo, posicao = otimizacao.optimize(funcao_obj, iters=n_iteracoes, verbose=True)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-09-30 10:44:10,180 - pyswarms.single.global_best - INFO - Optimize for 50 iters with {'c1': 0.5, 'c2': 0.3, 'w': 0.9}\n",
      "pyswarms.single.global_best: 100%|██████████|50/50, best_cost=0.09\n",
      "2021-09-30 10:45:27,463 - pyswarms.single.global_best - INFO - Optimization finished | best cost: 0.09000342198703525, best pos: [0.10654743 0.62092787 1.2747798  ... 1.38686022 0.72895938 1.34096168]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Resultado do treinamento"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "print(\"Valor ótimo de minização: \", custo)\r\n",
    "print(\"Pesos otimizados da camada oculta:\\n\", posicao[:23520])\r\n",
    "print(\"Bias otimizados da camada oculta:\\n\", posicao[23520:23550])\r\n",
    "print(\"Pesos otimizados da camada de saída:\\n\", posicao[23550:23850])\r\n",
    "print(\"Bias otimizados da camada de saída:\\n\", posicao[23850:])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Valor ótimo de minização:  0.09000342198703525\n",
      "Pesos otimizados da camada oculta:\n",
      " [0.10654743 0.62092787 1.2747798  ... 0.73729872 1.06783897 1.76580412]\n",
      "Bias otimizados da camada oculta:\n",
      " [0.85476589 1.20788946 0.84565636 0.65468199 0.92206602 0.56331427\n",
      " 1.26841844 1.53388275 0.93781721 1.62169157 1.25714957 1.27754267\n",
      " 0.40466071 1.07002829 0.64533509 1.44556088 0.98863151 0.88100048\n",
      " 1.25358453 0.80911349 0.95618924 0.62997516 1.18562282 0.49596633\n",
      " 1.09236201 1.11387032 0.54616588 1.10226981 0.83829444 0.73735979]\n",
      "Pesos otimizados da camada de saída:\n",
      " [ 1.17199042  0.5441611   0.96603615  1.39268983  1.51971124  1.52193096\n",
      "  1.0824194   0.63691687  0.82911556  1.00713103  0.99636289  0.64288862\n",
      "  1.69681279  0.44582437  0.93265744  0.96907176  0.98956137  1.07036405\n",
      "  0.28795654  1.93738938  1.91944197  1.09085951  0.89130465  0.86535039\n",
      "  1.25489785  1.32557819  0.87999412  1.1027951   0.1968381   1.19065259\n",
      "  0.43864245  1.09295643  0.77114032  1.08199822  1.01341859  1.11797165\n",
      "  1.00703164  0.68921608  0.51773631  0.51609105  0.50769066  0.5048106\n",
      "  0.27715995  1.41186473  1.20695285  0.40462428  1.44361896  1.41709748\n",
      "  1.39189973 -0.52708354  0.74206959  0.39434022  1.21166091  0.69936975\n",
      "  0.78774652 -0.11355253 -0.12116097  0.46702673  0.54028905  0.61878302\n",
      "  0.65994952  1.7194256   0.98230265  0.99477403  1.3895025   1.26920101\n",
      "  1.47040497  1.47753021  1.22273672  1.22709036  0.88124959  1.86951192\n",
      "  1.15484527  0.83480662  1.08374547  0.19049322  0.50353926  1.36270566\n",
      "  1.30887674  1.1526918   0.47824479  0.70868356  0.83629304  1.24658811\n",
      "  1.38001259  1.07966336  1.01478289  0.85403996  1.07346338  1.52305917\n",
      "  1.35278469  0.28249401  1.43775912  0.76467776  0.71750261  1.24596506\n",
      "  1.27467647  0.55066206  1.04879116  0.7822971   1.25067128  0.53158515\n",
      "  1.00993437  0.35874596  1.36742415  1.16970626  1.31453815  0.99863692\n",
      "  0.26629739  0.68579235  1.08615263  0.97631526  1.6442344   1.26394689\n",
      "  0.38404689  0.90126908  1.59255683  1.8191834   1.22840609  1.41717947\n",
      "  0.41667831  1.14081972  0.79691682  1.3092343   0.65305354  0.46196409\n",
      "  1.15368668  1.45346831  1.49960774  0.95075389  0.54087063  0.89208511\n",
      "  1.59698032  0.92898458  0.74366702  1.17876542  1.53160524  1.42767541\n",
      "  1.2418598   1.48156156  1.06999286  1.14234336  0.98070423  1.48290865\n",
      "  1.18660016  1.06080103  1.08955982  0.40231385  0.93937489  0.72205742\n",
      "  1.21211291  0.97818256  1.05859862  1.3196098   1.22870347  0.91032677\n",
      "  1.36065224  0.61345956  0.62752659  0.46723604  0.9905436   0.93315883\n",
      "  1.17140376  0.99695512 -0.15282589  1.08778106  1.19545408  0.26486109\n",
      "  0.59371914  0.35990513  0.15101535  0.67843985  0.29711101  1.69052821\n",
      "  0.76208426  0.63589342  0.28812877  0.20428805  1.42425635  0.32893644\n",
      "  1.2766104   1.29560435  0.76792693  1.29617124  1.06871605  1.00296625\n",
      "  0.95164658  1.1501725   1.20473868  1.28894063  0.94853879  1.12121407\n",
      "  1.56721539  1.11064679  0.50559355  0.78210003  1.86755657  1.33989762\n",
      "  1.61888985  0.79622015  0.68382339  1.44589466  1.46017409  0.29841291\n",
      "  0.23890753  1.23665805  1.15737319  1.21283157  0.46341881  1.75281117\n",
      "  1.28570819  1.15439328  0.70585132  0.67965953  0.41713388  1.1856408\n",
      "  0.12658397  1.5148973   0.69664727  0.99320021  0.61849826  1.31841987\n",
      "  0.80742791  0.90030527  1.4214893   0.98593872  0.70527255  0.36777992\n",
      "  1.54034681  0.7297132   0.44053686  1.31226372  0.52415022  0.57558416\n",
      "  1.19245955  1.00652757  0.64265859  0.92180328  1.5469915   1.39633461\n",
      "  0.93946151  1.38415456  0.87017636  1.45889118  1.23118944  1.43323047\n",
      "  0.38357316  0.7532061   1.15155263  1.82234512  0.44062529  1.3740221\n",
      "  0.98239988  1.15883821  1.63380012  0.37647235  1.32441902  0.93086571\n",
      "  1.07035024  0.9879956   0.44040487  0.57974004  0.69952803  1.31715181\n",
      "  1.2741838   1.92143373  1.31761452  1.47222117  0.8080644   1.2190217\n",
      "  1.08476933  1.2839002   0.96908324  1.12548198  1.21176775  1.69822451\n",
      "  1.22484138  1.25197267  1.30271442  1.79730248  1.00385533  0.75205316\n",
      "  1.46908238  1.13273353  1.16073844  1.58124751  0.28145894  1.11500196\n",
      "  2.00197877  0.72380152  0.0716844   1.29957087  1.41791655  0.37349022\n",
      "  1.317709    0.92700356  0.90885376  1.05670135  0.84770467  1.03357901]\n",
      "Bias otimizados da camada de saída:\n",
      " [0.94547829 1.36504471 0.21067481 1.23455563 1.10893058 0.80511209\n",
      " 1.50328103 1.38686022 0.72895938 1.34096168]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Avaliação do treinamento e do teste"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "# Calculando a acurácia\r\n",
    "def avaliacao(posicao):\r\n",
    "    y_obtido = ativacao1(posicao)\r\n",
    "    #y_obtido = ativacao2(y_obtido)\r\n",
    "    resultado = np.argmax(y_obtido, axis=1)\r\n",
    "    return y_obtido, resultado"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "# Acurácia do treino\r\n",
    "n = len(amostras)\r\n",
    "correct_log = np.zeros(len(y_desejado))\r\n",
    "\r\n",
    "y_obtido, result_av = avaliacao(posicao)\r\n",
    "\r\n",
    "print(\"Acurácia de treino: \", np.mean(y_obtido == y_desejado))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Acurácia de treino:  0.0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Execução e avaliação do teste"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "# Guardando dados de entrada e as saídas desejadas para cada amostra de teste\r\n",
    "test_data = list(test_data)\r\n",
    "amostras = []\r\n",
    "y_desejado = []\r\n",
    "p = 0\r\n",
    "for amostra in test_data:\r\n",
    "    aux = []\r\n",
    "    for i in amostra[0]:\r\n",
    "        aux.append(i[0])\r\n",
    "    amostras.append(aux)\r\n",
    "    \r\n",
    "    #converte decimal para binário e guarda em vetor de 10 posições\r\n",
    "    y = np.zeros(10)\r\n",
    "    vetor = list(map(int, bin(amostra[1]).replace(\"0b\", \"\")))\r\n",
    "    for i in range(1, len(vetor)+1):\r\n",
    "        y[-i] = vetor[-i]\r\n",
    "    y_desejado.append(y)\r\n",
    "    \r\n",
    "    if p == 199:\r\n",
    "        break\r\n",
    "    p += 1\r\n",
    "\r\n",
    "amostras = np.array(amostras)\r\n",
    "y_desejado = np.array(y_desejado)\r\n",
    "\r\n",
    "# Acurácia do treino\r\n",
    "correct_log = np.zeros(len(y_desejado))\r\n",
    "y_obtido, result_av = avaliacao(posicao)\r\n",
    "\r\n",
    "print(\"Acurácia de teste: \", np.mean(y_obtido == y_desejado))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Acurácia de teste:  0.0\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "4c4c8cfd539e0411d3cc5c1e72b05a7dbcf36342c56df37f381a6ef1a534e6cb"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}